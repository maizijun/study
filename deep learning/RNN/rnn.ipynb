{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# from gensim.test.utils import common_texts,get_tmpfile\n",
    "from gensim.models import word2vec\n",
    "from gensim import corpora\n",
    "\n",
    "\n",
    "from nltk.corpus import reuters,stopwords,brown\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize,RegexpTokenizer\n",
    "# from nltk import Text\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('..\\\\..\\\\NLP')\n",
    "from word2vec_preprocess import *\n",
    "# from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2000 10240\n242000 14340\n"
    }
   ],
   "source": [
    "text_ls = gen_text(2000)\n",
    "sen_ls = gen_sentence(text_ls)\n",
    "\n",
    "print(len(text_ls),len(sen_ls))\n",
    "\n",
    "word_sen_ls = []\n",
    "word_ls = []\n",
    "\n",
    "for xx in sen_ls:\n",
    "    word_sen_ls.append(gen_word(xx))\n",
    "    word_ls = word_ls + gen_word(xx)\n",
    "\n",
    "\n",
    "vocab = np.unique(word_ls)\n",
    "print(len(word_ls),len(vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1461\n"
    }
   ],
   "source": [
    "word_ls = pd.Series(word_ls)\n",
    "wc = word_ls.value_counts()\n",
    "is_select = (wc>=20) * (wc<=5000)\n",
    "\n",
    "# is_common_word = word_ls[is_select.values]\n",
    "vocab = is_select[is_select==True].index.tolist()\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       vec_0   vec_1   vec_2   vec_3   vec_4   vec_5   vec_6   vec_7   vec_8  \\\nsaid -0.3698  0.3696  0.3963  0.4458 -0.6512  -0.883  0.0827  1.3464  0.1074   \nand   -0.145  0.4768  0.0581   0.062  -0.718 -0.1272  0.2745  0.2334  0.0191   \na    -0.3445    0.29   0.008 -0.0287 -0.9272 -0.4071  0.3112  0.0827 -0.0772   \nmln  -0.2749  0.8201 -0.5405 -0.1533  -1.359  0.3779  0.5692 -0.5865 -1.1716   \nfor  -0.1593  0.4789 -0.1663  0.2015 -0.9665 -0.2836  0.3011 -0.0113 -0.2179   \n\n       vec_9   ...    vec_90  vec_91  vec_92  vec_93  vec_94  vec_95  vec_96  \\\nsaid  0.1266   ...   -0.8156   0.351 -1.0272  0.3028 -0.0771 -0.3193 -0.2752   \nand   0.2254   ...   -0.4696 -0.2244 -0.4051  0.0807  0.5272  0.3785  -0.347   \na     0.1188   ...    0.0821 -0.1983 -0.1212  0.4562   0.171  0.2468   0.043   \nmln  -0.1018   ...    -0.348 -0.6756 -0.2584  0.5707  0.6061  1.1029   0.063   \nfor   0.1938   ...   -0.2255  -0.358 -0.2739  0.3162  0.2152  0.4208 -0.0376   \n\n      vec_97  vec_98  vec_99  \nsaid -0.0613  -0.493   0.909  \nand  -0.0491  0.0785  0.2603  \na    -0.3071   0.162  0.4359  \nmln  -0.5164   1.216  0.6045  \nfor  -0.2174  0.4478  0.5019  \n\n[5 rows x 100 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>vec_0</th>\n      <th>vec_1</th>\n      <th>vec_2</th>\n      <th>vec_3</th>\n      <th>vec_4</th>\n      <th>vec_5</th>\n      <th>vec_6</th>\n      <th>vec_7</th>\n      <th>vec_8</th>\n      <th>vec_9</th>\n      <th>...</th>\n      <th>vec_90</th>\n      <th>vec_91</th>\n      <th>vec_92</th>\n      <th>vec_93</th>\n      <th>vec_94</th>\n      <th>vec_95</th>\n      <th>vec_96</th>\n      <th>vec_97</th>\n      <th>vec_98</th>\n      <th>vec_99</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>said</th>\n      <td>-0.3698</td>\n      <td>0.3696</td>\n      <td>0.3963</td>\n      <td>0.4458</td>\n      <td>-0.6512</td>\n      <td>-0.883</td>\n      <td>0.0827</td>\n      <td>1.3464</td>\n      <td>0.1074</td>\n      <td>0.1266</td>\n      <td>...</td>\n      <td>-0.8156</td>\n      <td>0.351</td>\n      <td>-1.0272</td>\n      <td>0.3028</td>\n      <td>-0.0771</td>\n      <td>-0.3193</td>\n      <td>-0.2752</td>\n      <td>-0.0613</td>\n      <td>-0.493</td>\n      <td>0.909</td>\n    </tr>\n    <tr>\n      <th>and</th>\n      <td>-0.145</td>\n      <td>0.4768</td>\n      <td>0.0581</td>\n      <td>0.062</td>\n      <td>-0.718</td>\n      <td>-0.1272</td>\n      <td>0.2745</td>\n      <td>0.2334</td>\n      <td>0.0191</td>\n      <td>0.2254</td>\n      <td>...</td>\n      <td>-0.4696</td>\n      <td>-0.2244</td>\n      <td>-0.4051</td>\n      <td>0.0807</td>\n      <td>0.5272</td>\n      <td>0.3785</td>\n      <td>-0.347</td>\n      <td>-0.0491</td>\n      <td>0.0785</td>\n      <td>0.2603</td>\n    </tr>\n    <tr>\n      <th>a</th>\n      <td>-0.3445</td>\n      <td>0.29</td>\n      <td>0.008</td>\n      <td>-0.0287</td>\n      <td>-0.9272</td>\n      <td>-0.4071</td>\n      <td>0.3112</td>\n      <td>0.0827</td>\n      <td>-0.0772</td>\n      <td>0.1188</td>\n      <td>...</td>\n      <td>0.0821</td>\n      <td>-0.1983</td>\n      <td>-0.1212</td>\n      <td>0.4562</td>\n      <td>0.171</td>\n      <td>0.2468</td>\n      <td>0.043</td>\n      <td>-0.3071</td>\n      <td>0.162</td>\n      <td>0.4359</td>\n    </tr>\n    <tr>\n      <th>mln</th>\n      <td>-0.2749</td>\n      <td>0.8201</td>\n      <td>-0.5405</td>\n      <td>-0.1533</td>\n      <td>-1.359</td>\n      <td>0.3779</td>\n      <td>0.5692</td>\n      <td>-0.5865</td>\n      <td>-1.1716</td>\n      <td>-0.1018</td>\n      <td>...</td>\n      <td>-0.348</td>\n      <td>-0.6756</td>\n      <td>-0.2584</td>\n      <td>0.5707</td>\n      <td>0.6061</td>\n      <td>1.1029</td>\n      <td>0.063</td>\n      <td>-0.5164</td>\n      <td>1.216</td>\n      <td>0.6045</td>\n    </tr>\n    <tr>\n      <th>for</th>\n      <td>-0.1593</td>\n      <td>0.4789</td>\n      <td>-0.1663</td>\n      <td>0.2015</td>\n      <td>-0.9665</td>\n      <td>-0.2836</td>\n      <td>0.3011</td>\n      <td>-0.0113</td>\n      <td>-0.2179</td>\n      <td>0.1938</td>\n      <td>...</td>\n      <td>-0.2255</td>\n      <td>-0.358</td>\n      <td>-0.2739</td>\n      <td>0.3162</td>\n      <td>0.2152</td>\n      <td>0.4208</td>\n      <td>-0.0376</td>\n      <td>-0.2174</td>\n      <td>0.4478</td>\n      <td>0.5019</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 100 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 294
    }
   ],
   "source": [
    "wv_model = word2vec.Word2Vec(word_sen_ls,size=100,window=5)\n",
    "model_vocab = list(wv_model.wv.vocab.keys())\n",
    "\n",
    "df_word_vec = pd.DataFrame(index=vocab,columns=['vec_'+str(i) for i in range(100)])\n",
    "\n",
    "for i,word in enumerate(df_word_vec.index[:]):\n",
    "    df_word_vec.loc[word] = wv_model.wv.word_vec(word).round(4)\n",
    "\n",
    "\n",
    "df_word_vec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(1461, 100)"
     },
     "metadata": {},
     "execution_count": 295
    }
   ],
   "source": [
    "df_word_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('reaffirmed', 0.9989835023880005),\n ('crisis', 0.9989787340164185),\n ('met', 0.9988820552825928),\n ('strength', 0.9987492561340332),\n ('expansion', 0.99871426820755),\n ('direction', 0.9986786842346191),\n ('governments', 0.9986090660095215),\n ('gulf', 0.9984222650527954),\n ('mexico', 0.9983996152877808),\n ('mideast', 0.9983780980110168)]"
     },
     "metadata": {},
     "execution_count": 296
    }
   ],
   "source": [
    "wv_model.wv.most_similar('news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_x_y(sentence):\n",
    "\n",
    "    window = 4\n",
    "    n = len(sentence)\n",
    "    if n<=window:\n",
    "        pass\n",
    "\n",
    "    x_input = []\n",
    "    y_input = []\n",
    "\n",
    "    for k in range(n-4): #### 遍历句子长度 ####\n",
    "        # for w in range(window): #### 对窗口内所有单词组合全部拿出来 #### 使用t~t+3单词预测t+4\n",
    "        x_tmp,y_tmp = sentence[k:k+window],sentence[k+window]\n",
    "\n",
    "        x_input.append(x_tmp)\n",
    "        y_input.append(y_tmp)\n",
    "\n",
    "        # print(x_tmp,y_tmp)\n",
    "\n",
    "    x_input = pd.DataFrame(x_input)\n",
    "    y_input = pd.DataFrame(y_input)\n",
    "\n",
    "    return x_input,y_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame()\n",
    "y = pd.DataFrame()\n",
    "\n",
    "for sen in word_sen_ls[:]:\n",
    "\n",
    "    sen = list(filter(lambda x:x in vocab,sen))\n",
    "\n",
    "    X_tmp,y_tmp = gen_x_y(sen)\n",
    "\n",
    "    X = pd.concat([X,X_tmp])\n",
    "    y = pd.concat([y,y_tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((127777, 4), (127777, 1))"
     },
     "metadata": {},
     "execution_count": 299
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(1461, 1461)"
     },
     "metadata": {},
     "execution_count": 300
    }
   ],
   "source": [
    "len(np.unique(X)),len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X[~X.isin(vocab)]='the'\n",
    "# y[~y.isin(vocab)]='the'\n",
    "\n",
    "# y.isin(vocab).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.iloc[0,0] = df_word_vec.loc['the'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(127777, 4)"
     },
     "metadata": {},
     "execution_count": 303
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series(X.values.ravel()).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "           0        1        2        3\n0  exporters   damage     from    trade\n1     damage     from    trade  between\n2       from    trade  between       us\n3      trade  between       us      and\n4    between       us      and    japan",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>exporters</td>\n      <td>damage</td>\n      <td>from</td>\n      <td>trade</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>damage</td>\n      <td>from</td>\n      <td>trade</td>\n      <td>between</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>from</td>\n      <td>trade</td>\n      <td>between</td>\n      <td>us</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>trade</td>\n      <td>between</td>\n      <td>us</td>\n      <td>and</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>between</td>\n      <td>us</td>\n      <td>and</td>\n      <td>japan</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 349
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         0\n0  between\n1       us\n2      and\n3    japan\n4      has",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>between</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>us</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>and</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>japan</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>has</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 353
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_input = np.zeros(shape=[X.shape[0],X.shape[1],100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(127777, 4, 100)"
     },
     "metadata": {},
     "execution_count": 308
    }
   ],
   "source": [
    "X_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_input[0,0] = df_word_vec.loc[X.iloc[0,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0\n1000\n2000\n3000\n4000\n5000\n6000\n7000\n8000\n9000\n10000\n11000\n12000\n13000\n14000\n15000\n16000\n17000\n18000\n19000\n20000\n21000\n22000\n23000\n24000\n25000\n26000\n27000\n28000\n29000\n30000\n31000\n32000\n33000\n34000\n35000\n36000\n37000\n38000\n39000\n40000\n41000\n42000\n43000\n44000\n45000\n46000\n47000\n48000\n49000\n50000\n51000\n52000\n53000\n54000\n55000\n56000\n57000\n58000\n59000\n60000\n61000\n62000\n63000\n64000\n65000\n66000\n67000\n68000\n69000\n70000\n71000\n72000\n73000\n74000\n75000\n76000\n77000\n78000\n79000\n80000\n81000\n82000\n83000\n84000\n85000\n86000\n87000\n88000\n89000\n90000\n91000\n92000\n93000\n94000\n95000\n96000\n97000\n98000\n99000\n100000\n101000\n102000\n103000\n104000\n105000\n106000\n107000\n108000\n109000\n110000\n111000\n112000\n113000\n114000\n115000\n116000\n117000\n118000\n119000\n120000\n121000\n122000\n123000\n124000\n125000\n126000\n127000\n"
    }
   ],
   "source": [
    "for i in range(X_input.shape[0]):\n",
    "\n",
    "    if i%1000==0:\n",
    "        print(i)\n",
    "\n",
    "    for j in range(X_input.shape[1]):\n",
    "        X_input[i,j] = df_word_vec.loc[X.iloc[i,j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_input = X.values[:,:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(127777, 4, 100)"
     },
     "metadata": {},
     "execution_count": 312
    }
   ],
   "source": [
    "X_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(127777, 4)"
     },
     "metadata": {},
     "execution_count": 314
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "# ohe = OrdinalEncoder()\n",
    "ohe.fit(np.array(vocab).reshape(-1,1))\n",
    "\n",
    "# X_trans = X.apply(lambda x:np.squeeze(ohe.transform(x.reshape(-1,1)),axis=1))\n",
    "# y_trans = y.apply(lambda x:np.squeeze(ohe.transform(y[0].reshape(-1,1))))\n",
    "y_trans = ohe.transform(y).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "72"
     },
     "metadata": {},
     "execution_count": 343
    }
   ],
   "source": [
    "np.argmax(ohe.transform(np.array([['and']])).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### RNN CELL ####\n",
    "rnn_mod = 1\n",
    "num_unit = 128\n",
    "\n",
    "if rnn_mod==1:\n",
    "    cell = tf.nn.rnn_cell.BasicRNNCell(num_units=num_unit)\n",
    "if rnn_mod==2:\n",
    "    cell = tf.nn.rnn_cell.LSTMCell(num_units=num_unit)\n",
    "if rnn_mod==3:\n",
    "    cell = tf.nn.rnn_cell.GRUCell(num_units=num_unit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x = tf.placeholder(tf.float32,[None,4,100])\n",
    "input_y = tf.placeholder(tf.float32,[None,len(vocab)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed_size = 100\n",
    "\n",
    "# word_embeddings = tf.Variable(tf.truncated_normal([vob_size,embed_size],stddev=1,mean=0.1))\n",
    "# embedding_word_ids = tf.nn.embedding_lookup(word_embeddings,input_x)\n",
    "\n",
    "# weights = tf.Variable(tf.truncated_normal([vob_size,embed_size],mean=1,stddev=1))\n",
    "# # bias = tf.Variable(tf.truncated_normal([vob_size]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Tensor(\"rnn1_7/rnn/transpose_1:0\", shape=(?, 4, 128), dtype=float32) Tensor(\"rnn1_7/rnn/while/Exit_3:0\", shape=(?, 128), dtype=float32)\n"
    }
   ],
   "source": [
    "\n",
    "# tf.reset_default_graph()\n",
    "#create a BasicRNNCell\n",
    "\n",
    "with tf.variable_scope('rnn1',reuse=tf.AUTO_REUSE):\n",
    "\n",
    "    rnn_cell = tf.nn.rnn_cell.BasicRNNCell(num_units=128)\n",
    "    # rnn_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units=128)\n",
    "    # rnn_cell = tf.nn.rnn_cell.GRUCell(num_units=128)\n",
    "\n",
    "    #'outputs' is a tensor of shape [batch_size, max_time, cell_state_size]\n",
    "\n",
    "    #defining initial state\n",
    "    initial_state = tf.placeholder(tf.float32,[None,128])\n",
    "\n",
    "    #'state' is a tensor of shape [batch_size, cell_state_size]\n",
    "    outputs, state = tf.nn.dynamic_rnn(cell=rnn_cell,inputs=input_x,dtype=tf.float32)\n",
    "\n",
    "    print(outputs, state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_drop = tf.layers.dropout(0.2)\n",
    "\n",
    "with tf.variable_scope('logit2',reuse=tf.AUTO_REUSE):\n",
    "    logits = tf.layers.dense(state,units=3000)\n",
    "    logits2 = tf.layers.dense(state,units=len(vocab))\n",
    "\n",
    "    error = tf.subtract(input_y,logits2)\n",
    "    loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits_v2(labels=input_y,logits=logits2))\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.0002).minimize(loss)\n",
    "\n",
    "\n",
    "tf.summary.scalar('loss',loss)\n",
    "summ_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Operation 'logit2/Adam' type=NoOp>"
     },
     "metadata": {},
     "execution_count": 330
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for embedding loss\n",
    "# loss = tf.reduce_sum(\n",
    "#     tf.nn.sampled_softmax_loss(weights=weights,\n",
    "#                                 biases = bias,\n",
    "#                                 labels = input_y,\n",
    "#                                 inputs = embedding_word_ids,\n",
    "#                                 num_sampled = 20,\n",
    "#                                 num_classes = vob_size\n",
    "#                                 ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0 7295.3413\n10 7207.38\n20 7141.4883\n30 6987.3774\n40 6831.203\n50 6723.9097\n60 6530.462\n70 6412.95\n80 6315.078\n90 6319.9604\n0 6381.051\n10 6063.3994\n20 6321.379\n30 6188.9287\n40 6150.1025\n50 6295.8955\n60 6161.251\n70 6185.363\n80 6133.0503\n90 6214.706\n0 6344.081\n10 5904.896\n20 6245.7637\n30 6054.5986\n40 6035.6436\n50 6233.875\n60 6061.6616\n70 6093.677\n80 6036.61\n90 6158.4307\n0 6301.8184\n10 5784.8667\n20 6185.036\n30 5941.638\n40 5941.464\n50 6184.0166\n60 5987.222\n70 6020.789\n80 5962.2305\n90 6117.17\n0 6268.655\n10 5711.8374\n20 6146.4985\n30 5870.209\n40 5879.628\n50 6148.0425\n60 5937.5967\n70 5965.798\n80 5908.637\n90 6082.5747\n0 6240.6416\n10 5660.191\n20 6115.365\n30 5815.7275\n40 5831.6675\n50 6115.114\n60 5897.397\n70 5921.334\n80 5865.314\n90 6052.4717\n0 6216.021\n10 5618.3945\n20 6086.9004\n30 5771.588\n40 5790.9077\n50 6085.4316\n60 5863.4097\n70 5884.6406\n80 5826.5977\n90 6026.3594\n0 6194.132\n10 5584.2256\n20 6060.8203\n30 5733.3384\n40 5754.6494\n50 6058.5303\n60 5832.9707\n70 5852.1816\n80 5791.455\n90 6003.2236\n0 6173.8867\n10 5554.6753\n20 6036.725\n30 5698.4224\n40 5721.619\n50 6033.8184\n60 5804.426\n70 5822.0156\n80 5759.3687\n90 5982.382\n0 6154.8857\n10 5528.0244\n20 6014.3643\n30 5665.7847\n40 5691.257\n50 6010.9287\n60 5777.3633\n70 5792.864\n80 5729.7803\n90 5962.9375\n"
    }
   ],
   "source": [
    "train_log_path = \"C:/Users/qqmai/Desktop/study/deep learning/tmp/train_tmp\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    init=tf.global_variables_initializer()\n",
    "    sess.run([init])\n",
    "\n",
    "    summary_writer_tr = tf.summary.FileWriter(train_log_path, graph=sess.graph)\n",
    "\n",
    "    batch_size = 1000\n",
    "\n",
    "    for ii in range(1000):\n",
    "        i = ii%100\n",
    "        _,loss_tmp,smm = sess.run([optimizer,loss,summ_op],\n",
    "                            feed_dict={input_x:X_input[batch_size*i:batch_size*(i+1)],\n",
    "                                      input_y:y_trans[batch_size*i:batch_size*(i+1)]})\n",
    "\n",
    "        summary_writer_tr.add_summary(smm,ii)\n",
    "\n",
    "\n",
    "        if i%10==0:\n",
    "            print(i,loss_tmp)\n",
    "\n",
    "        \n",
    "    y_pred = sess.run(logits2,feed_dict=({input_x:X_input}))\n",
    "\n",
    "summary_writer_tr.close()\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2"
     },
     "metadata": {},
     "execution_count": 362
    }
   ],
   "source": [
    "# 22//10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([1393, 1432,   72,   72,   72,  504,   72,   72,   72,   72],\n      dtype=int64)"
     },
     "metadata": {},
     "execution_count": 348
    }
   ],
   "source": [
    "np.apply_along_axis(lambda x:np.argmax(x),1,y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([3.3258963, 3.3662004, 3.3701138, 3.3707998, 3.3550406, 3.3436682,\n       3.3490684, 3.3465526, 3.3631418, 3.3563485, 3.3418279, 3.3773727,\n       3.375233 , 3.3444042, 3.3597507, 3.3397362, 3.3618507, 3.3771994,\n       3.3802953, 3.3570595, 3.366798 , 3.3493881, 3.307503 , 3.320223 ,\n       3.312397 , 3.318333 , 3.3782504, 3.3586054, 3.3645713, 3.3790708,\n       3.3254762, 3.3486302, 3.3873694, 3.3716464, 3.3900445, 3.342552 ,\n       3.2104769, 3.2315495, 3.3513896, 3.4010973, 3.3164034, 3.3858533,\n       3.326925 , 3.2544281, 3.156462 , 3.227486 , 3.372555 , 3.3729856,\n       3.3626654, 3.32598  , 3.3576622, 3.3706458, 3.3052306, 3.2808628,\n       3.317006 , 3.3447092, 3.2765868, 3.3626883, 3.340518 , 3.3262165,\n       3.3678746, 3.3806834, 3.3778763, 3.3818972, 3.3794982, 3.3529086,\n       3.3382385, 3.336514 , 3.3588762, 3.2737567, 3.1937103, 3.2642863,\n       3.2994494, 3.356535 , 3.315668 , 3.3406982, 3.3100796, 3.27799  ,\n       3.342139 , 3.4026654, 3.3705902, 3.3323433, 3.3684015, 3.3433042,\n       3.348367 , 3.3756037, 3.2855983, 3.3875806, 3.3522353, 3.3525634,\n       3.3490732, 3.365305 , 3.3227234, 3.339983 , 3.2950497, 3.3011234,\n       3.2492583, 3.3252966, 3.3199103, 3.3442338], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 339
    }
   ],
   "source": [
    "y_pred[:100][:,72]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(1154, 1)"
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_trans.values[:,:,np.newaxis].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector2 = np.dot(wgs,vector1)\n",
    "order2 = vector2.argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([['export'],\n       ['government'],\n       ['said'],\n       ['company'],\n       ['likely'],\n       ['expected'],\n       ['market'],\n       ['exchange'],\n       ['spokesman'],\n       ['last']], dtype='<U19')"
     },
     "metadata": {},
     "execution_count": 162
    }
   ],
   "source": [
    "ohe.inverse_transform(order2[:10,np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[1, 2, 3]"
     },
     "metadata": {},
     "execution_count": 77
    }
   ],
   "source": [
    "1 * [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36464bitqqmaivirtualenv362ad2a659b5435fb171141c56735108",
   "display_name": "Python 3.6.4 64-bit ('qqmai': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}